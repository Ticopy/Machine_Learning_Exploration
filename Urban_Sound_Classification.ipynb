{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Urban_Sound_Classification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1FqSI4qdDdhcJumj2n4U62nqiN8VZY5Bn",
      "authorship_tag": "ABX9TyPNlXeggV5c6dVxfd/lUuIP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ticopy/Machine_Learning_Exploration/blob/main/Urban_Sound_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9aK9wqTOSpB"
      },
      "source": [
        "Import the Data (.wav files) from google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgID4UKFD7WQ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJCFjDo8O80f"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd28KCZmPB-Z"
      },
      "source": [
        "!unzip 'drive/MyDrive/Hackathlon/001_Urban_Sound_Classification/train.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nsb4-5vxPcC9"
      },
      "source": [
        "Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBND3lnUPalm"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import librosa\n",
        "import pickle\n",
        "import glob\n",
        "import IPython.display as ipd\n",
        "%pylab inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ0dLiMMQJFu"
      },
      "source": [
        "Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wXIc0-BQM0X"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Hackathlon/001_Urban_Sound_Classification/train_fuSp8nd.csv')\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Count of datapoints in each class\n",
        "df[\"Class\"].value_counts()"
      ],
      "metadata": {
        "id": "Kd1eSn5x_xwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8WcQOWKSAUg"
      },
      "source": [
        "ipd.Audio('Train/1.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGwhfC3eTXY2"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KC3pDjpVWqz9"
      },
      "source": [
        "Preprocessing strategy, \n",
        "for each file :\n",
        ">1. load a file\n",
        ">2. pad the signal (if necessary)\n",
        ">3. extracting log spectrogram from signal\n",
        ">4. normalise spectrogram\n",
        ">5. save the normalised spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q6sP6ewX3gD"
      },
      "source": [
        "class Loader:\n",
        "  #Loader is responsible for loading an audio file\n",
        "  def __init__(self, sample_rate, duration, mono):\n",
        "    self.sample_rate = sample_rate\n",
        "    self.duration = duration\n",
        "    self.mono = mono\n",
        "\n",
        "  #need \"librosa\" module\n",
        "  def load(self, file_path):\n",
        "    signal = librosa.load(file_path,\n",
        "                          sr=self.sample_rate,\n",
        "                          duration=self.duration,\n",
        "                          mono=self.mono)[0]\n",
        "    return signal\n",
        "\n",
        "class Padder:\n",
        "  #Padder is responsible to apply padding to an array\n",
        "  def __init__(self, mode=\"constant\"):\n",
        "    self.mode = mode\n",
        "\n",
        "  #need \"numpy\" module\n",
        "  def right_pad(self, array, num_missing_item):\n",
        "    padded_array = np.pad(array,\n",
        "                          (0,num_missing_item),\n",
        "                          mode=self.mode)\n",
        "    return padded_array\n",
        "\n",
        "class LogSpectrogramExtractor:\n",
        "  #LogSpectrogramExtractor extracts log spectrogram (in dB) from a time-serie signal\n",
        "  def __init__(self, frame_size, hop_length):\n",
        "    self.frame_size = frame_size\n",
        "    self.hop_length = hop_length\n",
        "  \n",
        "  #need \"librosa\" and \"numpy\" modules\n",
        "  def extract(self, signal):\n",
        "    stft = librosa.stft(signal,\n",
        "                        n_fft=self.frame_size,\n",
        "                        hop_length=self.hop_length)[:-1]\n",
        "    spectrogram = np.abs(stft) \n",
        "    log_spectrogram = librosa.amplitude_to_db(spectrogram)\n",
        "    return log_spectrogram\n",
        "\n",
        "class MinMaxNormaliser:\n",
        "  #MinMaxNormaliser applies min max normalisation to an array\n",
        "  def __init__(self, min_val, max_val):\n",
        "    self.min = min_val\n",
        "    self.max = max_val\n",
        "\n",
        "  def normalise(self, array):\n",
        "    norm_array = (array - array.min()) / (array.max() - array.min())\n",
        "    norm_array = norm_array * (self.max - self.min) + self.min\n",
        "    return norm_array\n",
        "\n",
        "  def denormalise(self, norm_array, original_min, original_max):\n",
        "    array = (norm_array - self.min) / (self.max - self.min)\n",
        "    array = array * (original_max - original_min) + original_min\n",
        "    return array\n",
        "\n",
        "class Saver:\n",
        "  #Saver is responsible to save feature, and the min max values\n",
        "  def __init__(self, feature_save_dir, min_max_values_save_dir):\n",
        "    self.feature_save_dir = feature_save_dir\n",
        "    self.min_max_values_save_dir = min_max_values_save_dir\n",
        "\n",
        "  def save_feature(self, feature, file_path):\n",
        "    save_path = self._generate_save_path(file_path)\n",
        "    np.save(save_path, feature)\n",
        "\n",
        "  def save_min_max_values(self, min_max_values):\n",
        "    save_path = os.path.join(self.min_max_values_save_dir, \"min_max_value.pkl\")\n",
        "    self._save(min_max_values, save_path)\n",
        "\n",
        "  #need \"pickle\" module\n",
        "  @staticmethod\n",
        "  def _save(data,save_path):\n",
        "    with open(save_path, \"wb\") as f:\n",
        "      pickle.dump(data, f)\n",
        "\n",
        "  def _generate_save_path(self, file_path):\n",
        "    file_name = os.path.split(file_path)[1]\n",
        "    save_path = os.path.join(self.feature_save_dir, file_name + \".npy\")\n",
        "    return save_path\n",
        "\n",
        "\n",
        "class PreprocessingPipeline:\n",
        "  #PreprocessingPipeline process audio files in a directory\n",
        "  #Need to store the min and max value for all the log spectrogram\n",
        "\n",
        "  def __init__(self):\n",
        "    \n",
        "    self.padder = None\n",
        "    self.extractor = None\n",
        "    self.normaliser = None\n",
        "    self.saver = None\n",
        "    self.min_max_values = {}\n",
        "    self._loader = None\n",
        "    self._num_expected_samples = None\n",
        "\n",
        "  @property\n",
        "  def loader(self):\n",
        "    return self._loader\n",
        "\n",
        "  @loader.setter\n",
        "  def loader(self, loader):\n",
        "    self._loader = loader\n",
        "    self._num_expected_samples = int(loader.sample_rate * loader.duration)\n",
        "\n",
        "\n",
        "  def process(self, audio_file_dir):\n",
        "    for subdir, dirs, files in os.walk(audio_file_dir):\n",
        "        for file in files:\n",
        "          file_path = os.path.join(subdir, file)\n",
        "          if file_path.endswith(\".wav\"):\n",
        "            self._process_file(file_path)\n",
        "            print(f\"Processed file {file_path}\")\n",
        "    self.saver.save_min_max_values(self.min_max_values)\n",
        "\n",
        "\n",
        "  def _process_file(self, file_path):\n",
        "    signal = self.loader.load(file_path)\n",
        "    if self._is_padding_necessary(signal):\n",
        "      signal = self._apply_padding(signal)\n",
        "    feature = self.extractor.extract(signal)\n",
        "    norm_feature = self.normaliser.normalise(feature)\n",
        "    save_path = self.saver.save_feature(norm_feature, file_path)\n",
        "    self.store_min_max_value(save_path, feature.min(), feature.max())\n",
        "\n",
        "  def _is_padding_necessary(self, signal):\n",
        "    \n",
        "    if len(signal) < self._num_expected_samples:\n",
        "      return True\n",
        "    return False\n",
        "\n",
        "  def _apply_padding(self, signal):\n",
        "    num_missing_samples = self._num_expected_samples - len(signal)\n",
        "    padded_signal = self.padder.right_pad(signal, num_missing_samples)\n",
        "    return padded_signal\n",
        "  \n",
        "  def store_min_max_value(self, save_path, min_val, max_val):\n",
        "    self.min_max_values[save_path] = {\n",
        "        \"min\":min_val,\n",
        "        \"max\":max_val\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsGmWbMepzYx"
      },
      "source": [
        "FRAME_SIZE = 2048\n",
        "HOP_LENGTH = 1024\n",
        "DURATION = 4\n",
        "SAMPLE_RATE = 22050\n",
        "MONO = True\n",
        "\n",
        "SPECTOGRAMS_SAVE_DIR = \"/content/drive/MyDrive/Hackathlon/001_Urban_Sound_Classification/datasets/usc/spectrograms/\"\n",
        "MIN_MAX_VALUES_SAVE_DIR = \"/content/drive/MyDrive/Hackathlon/001_Urban_Sound_Classification/datasets/usc/\"\n",
        "FILES_DIR = \"/content/Train/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbaDC9DHZHQI"
      },
      "source": [
        "#Instantiate all objects\n",
        "loader = Loader(SAMPLE_RATE,DURATION,MONO)\n",
        "padder = Padder()\n",
        "log_spectrogram_extractor = LogSpectrogramExtractor(FRAME_SIZE, HOP_LENGTH)\n",
        "min_max_normaliser = MinMaxNormaliser(0, 1)\n",
        "saver = Saver(SPECTOGRAMS_SAVE_DIR, MIN_MAX_VALUES_SAVE_DIR)\n",
        "\n",
        "preprocessing_pipeline = PreprocessingPipeline()\n",
        "preprocessing_pipeline.loader = loader\n",
        "preprocessing_pipeline.padder = padder\n",
        "preprocessing_pipeline.extractor = log_spectrogram_extractor\n",
        "preprocessing_pipeline.normaliser = min_max_normaliser\n",
        "preprocessing_pipeline.saver = saver\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHAVadF0srmQ"
      },
      "source": [
        "preprocessing_pipeline.process(FILES_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing the data set"
      ],
      "metadata": {
        "id": "5dkUDuJaTS0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Spliting the dataset into labeled folder\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "DATASET_TRAIN_FILE_R = r\"/content/drive/MyDrive/Hackathlon/001_Urban_Sound_Classification/train_fuSp8nd.csv\"\n",
        "\n",
        "labels = pd.read_csv(DATASET_TRAIN_FILE_R)\n",
        "\n",
        "#Create 'train_sep' directory\n",
        "DATASET_DIR_PATH_R = r\"/content/drive/MyDrive/Hackathlon/001_Urban_Sound_Classification/datasets/usc/spectrograms/\"\n",
        "SEP_DIR_PATH_R = r\"/content/drive/MyDrive/Hackathlon/001_Urban_Sound_Classification/datasets/usc/labeled_spectro/\"\n",
        "\n",
        "if not os.path.exists(SEP_DIR_PATH_R):\n",
        "  os.mkdir(SEP_DIR_PATH_R)\n",
        "\n",
        "for filename, class_name in labels.values:\n",
        "  #Create subdirectory with \"class_name\"\n",
        "  if not os.path.exists(SEP_DIR_PATH_R + str(class_name)):\n",
        "    os.mkdir(SEP_DIR_PATH_R + str(class_name))\n",
        "\n",
        "  src_path = DATASET_DIR_PATH_R + str(filename) + '.wav.npy'\n",
        "  dst_path = SEP_DIR_PATH_R + str(class_name) + '/' + str(filename) + '.wav.npy'\n",
        "\n",
        "  print('Copy file {} to {}'.format(src_path,dst_path))\n",
        "  shutil.copy(src_path, dst_path)\n"
      ],
      "metadata": {
        "id": "simotHbiT7gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Spliting the dataset into labeled folder\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "DATASET_TRAIN_FILE_R = r\"/content/drive/MyDrive/Hackathlon/001_Urban_Sound_Classification/train_fuSp8nd.csv\"\n",
        "\n",
        "labels = pd.read_csv(DATASET_TRAIN_FILE_R)\n",
        "\n",
        "#Create 'train_sep' directory\n",
        "DATASET_DIR_PATH_R = r\"/content/Train/\"\n",
        "SEP_DIR_PATH_R = r\"/content/drive/MyDrive/Hackathlon/001_Urban_Sound_Classification/datasets/usc/labeled_wav/\"\n",
        "\n",
        "if not os.path.exists(SEP_DIR_PATH_R):\n",
        "  os.mkdir(SEP_DIR_PATH_R)\n",
        "\n",
        "for filename, class_name in labels.values:\n",
        "  #Create subdirectory with \"class_name\"\n",
        "  if not os.path.exists(SEP_DIR_PATH_R + str(class_name)):\n",
        "    os.mkdir(SEP_DIR_PATH_R + str(class_name))\n",
        "\n",
        "  src_path = DATASET_DIR_PATH_R + str(filename) + '.wav'\n",
        "  dst_path = SEP_DIR_PATH_R + str(class_name) + '/' + str(filename) + '.wav'\n",
        "\n",
        "  print('Copy file {} to {}'.format(src_path,dst_path))\n",
        "  shutil.copy(src_path, dst_path)\n"
      ],
      "metadata": {
        "id": "WJVoF8Nw0eNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving data into a JSON file\n",
        "\n",
        "import json\n",
        "import os\n",
        "import math\n",
        "import librosa\n",
        "\n",
        "DATASET_PATH = \"/content/drive/MyDrive/Hackathlon/001_Urban_Sound_Classification/datasets/usc/labeled_wav/\"\n",
        "JSON_PATH = \"/content/drive/MyDrive/Hackathlon/001_Urban_Sound_Classification/datasets/usc/data_usc_spectro.json\"\n",
        "SAMPLE_RATE = 22050\n",
        "TRACK_DURATION = 4 # measured in seconds\n",
        "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\n",
        "\n",
        "\n",
        "def save_spectro(dataset_path, json_path, n_fft=2048, hop_length=512, num_segments=1):\n",
        "    \"\"\"Extracts SpectroGrams from sound dataset and saves them into a json file along with class labels.\n",
        "        :param dataset_path (str): Path to dataset\n",
        "        :param json_path (str): Path to json file used to save MFCCs\n",
        "        :param num_spectro (int): Number of coefficients to extract\n",
        "        :param n_fft (int): Interval we consider to apply FFT. Measured in # of samples\n",
        "        :param hop_length (int): Sliding window for FFT. Measured in # of samples\n",
        "        :param: num_segments (int): Number of segments we want to divide sample tracks into\n",
        "        :return:\n",
        "        \"\"\"\n",
        "\n",
        "    # dictionary to store mapping, labels, and Spectrograms\n",
        "    data = {\n",
        "        \"mapping\": [],\n",
        "        \"labels\": [],\n",
        "        \"spectro\": []\n",
        "    }\n",
        "\n",
        "    samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
        "    num_spectro_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
        "\n",
        "    # loop through all genre sub-folder\n",
        "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
        "\n",
        "        # ensure we're processing a genre sub-folder level\n",
        "        if dirpath is not dataset_path:\n",
        "\n",
        "            # save genre label (i.e., sub-folder name) in the mapping\n",
        "            semantic_label = dirpath.split(\"/\")[-1]\n",
        "            data[\"mapping\"].append(semantic_label)\n",
        "            print(\"\\nProcessing: {}\".format(semantic_label))\n",
        "\n",
        "            # process all audio files in genre sub-dir\n",
        "            for f in filenames:\n",
        "\n",
        "\t\t            # load audio file\n",
        "                file_path = os.path.join(dirpath, f)\n",
        "                signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
        "\n",
        "                # process all segments of audio file\n",
        "                for d in range(num_segments):\n",
        "\n",
        "                    # calculate start and finish sample for current segment\n",
        "                    start = samples_per_segment * d\n",
        "                    finish = start + samples_per_segment\n",
        "\n",
        "                    # extract spectro\n",
        "                    spectro = librosa.feature.melspectrogram(signal[start:finish], sample_rate, n_fft=n_fft, hop_length=hop_length)\n",
        "                    spectro = spectro.T\n",
        "\n",
        "                    # store only mfcc feature with expected number of vectors\n",
        "                    if len(spectro) == num_spectro_vectors_per_segment:\n",
        "                        data[\"spectro\"].append(spectro.tolist())\n",
        "                        data[\"labels\"].append(i-1)\n",
        "                        print(\"{}, segment:{}\".format(file_path, d+1))\n",
        "\n",
        "    # save Spectros to json file\n",
        "    with open(json_path, \"w\") as fp:\n",
        "        json.dump(data, fp, indent=4)\n",
        "        \n",
        "        \n",
        "if __name__ == \"__main__\":\n",
        "    save_spectro(DATASET_PATH, JSON_PATH, num_segments=1)"
      ],
      "metadata": {
        "id": "5uIT7OCflJ81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13/03/2022\n",
        "Implementing a neural network for sound classification into multiple categories"
      ],
      "metadata": {
        "id": "4SA_rn4M729U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data\n",
        "#Split the data into train and test sets\n",
        "#Build the network architecture\n",
        "#Compile network\n",
        "#Train network\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "DATASET_PATH = \"/content/drive/MyDrive/Hackathlon/001_Urban_Sound_Classification/datasets/usc/data_usc_spectro.json\"\n",
        "\n",
        "def load_data(dataset_path):\n",
        "  with open(dataset_path, \"r\") as fp:\n",
        "    data = json.load(fp)\n",
        "  \n",
        "  # convert lists into numpy arrays\n",
        "  inputs = np.arrays(data[\"spectro\"])\n",
        "  targets = np.array(data[\"labels\"])\n",
        "\n",
        "  return inputs, targets\n",
        "\n",
        "if __name__ = \"__main__\":\n",
        "\n",
        "  #Load data\n",
        "  inputs, targets = load_data(DATASET_PATH)\n",
        "  \n",
        "  #Split the data into train and test sets\n",
        "  inputs_train, inputs_test, targets_train, targets_test = train_test_split(inputs, targets, test_size=0.2)\n",
        "\n",
        "  #Build the network architecture\n",
        "  model = keras.Sequential([\n",
        "                            # input layer\n",
        "                            keras.layers.Flatten(input_shape=(inputs.shape[1], inputs.shape[2])),\n",
        "\n",
        "                            # 1st hidden layer using Rectified Linear Unit (ReLU)\n",
        "                            keras.layers.Dense(512, activation=\"relu\"),\n",
        "\n",
        "                            # 2nd hidden layer using Rectified Linear Unit (ReLU)\n",
        "                            keras.layers.Dense(256, activation=\"relu\"),\n",
        "\n",
        "                            # 3rd hidden layer using Rectified Linear Unit (ReLU)\n",
        "                            keras.layers.Dense(64, activation=\"relu\"),\n",
        "                            \n",
        "                            # output layer\n",
        "                            keras.layers.Dense(10,activation=\"softmax\")\n",
        "                        ])\n",
        "  #Compile network\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "  model.compile(optimizer=optimizer, \n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=[\"accuracy\"])\n",
        "  \n",
        "  model.summary()\n",
        "\n",
        "  #Train network\n",
        "  #Types of batching choosen : Mini-batch\n",
        "  model.fit(inputs_train, targets_train, \n",
        "            validation_data=(inputs_test, targets_test),\n",
        "            epochs=50,\n",
        "            batch_size=32)\n",
        "  "
      ],
      "metadata": {
        "id": "WIPWwXvj70uU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}